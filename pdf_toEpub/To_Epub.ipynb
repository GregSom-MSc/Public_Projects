{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Create epub from html file.\n",
    "#### Author: Samuel Moreno\n",
    "\n",
    "****\n",
    "\n",
    "We are going to create an Epub document from a Gutenberg file (found in https://www.gutenberg.org), This code allows you to get a basic epub file, with a Cover Image and Table of Contents in order to transfer it to your Kindle or whatever.\n",
    "\n",
    "This project does not seek any commercial use, instead, it provides a nice training for us as Python programmers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from ebooklib import epub\n",
    "import os\n",
    "import re\n",
    "from html import escape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create functions to clean title and file contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_html(content):\n",
    "    \"\"\"Clean HTML to ensure compatibility\"\"\"\n",
    "    content = re.sub(r'<\\?xml[^>]*\\?>', '', content)\n",
    "    content = re.sub(r'<!DOCTYPE[^>]*>', '', content)\n",
    "    content = re.sub(r'</?o:[^>]*>', '', content)\n",
    "    content = re.sub(r'<\\w+:[^>]*>', '', content)\n",
    "    content = re.sub(r'xmlns:.*?=[\"\\'](.*?)[\"\\']', '', content)\n",
    "    # Remove empty tags\n",
    "    content = re.sub(r'<[^>]*?/\\s*>', '', content)\n",
    "    # Remove comments\n",
    "    content = re.sub(r'<!--.*?-->', '', content, flags=re.DOTALL)\n",
    "    return content\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"Clean title\"\"\"\n",
    "    title = re.sub(r'[^\\w\\s-]', '', title).strip()\n",
    "    title = re.sub('The Project Gutenberg eBook of ', '', title).strip()\n",
    "    return title if title else \"Default_Title\"\n",
    "\n",
    "def clean_toc(soup):\n",
    "    \"\"\"Remove duplicate table of contents and clean up volume headers\"\"\"\n",
    "    # Find the first CONTENTS header\n",
    "    first_toc = None\n",
    "    for header in soup.find_all(['h2']):\n",
    "        if header.get_text().strip().upper() == 'CONTENTS':\n",
    "            first_toc = header\n",
    "            break\n",
    "    \n",
    "    if first_toc:\n",
    "        # Find all content after this header until the next major section\n",
    "        current = first_toc.next_sibling\n",
    "        toc_content = []\n",
    "        while current and (not current.name in ['h2'] or \n",
    "                         (current.name == 'h2' and 'LIST OF ILLUSTRATIONS' not in current.get_text().upper())):\n",
    "            if isinstance(current, str) or current.name == 'p':\n",
    "                toc_content.append(current)\n",
    "            current = current.next_sibling\n",
    "        \n",
    "        # Keep only the content with links\n",
    "        for content in toc_content:\n",
    "            if isinstance(content, str):\n",
    "                continue\n",
    "            if not content.find('a'):\n",
    "                content.decompose()\n",
    "    \n",
    "    # Remove any additional CONTENTS sections\n",
    "    for header in soup.find_all(['h2']):\n",
    "        if header != first_toc and header.get_text().strip().upper() == 'CONTENTS':\n",
    "            # Remove the header and all following paragraphs until next header\n",
    "            current = header\n",
    "            while current and (isinstance(current, str) or current.name != 'h2'):\n",
    "                next_elem = current.next_sibling\n",
    "                current.decompose()\n",
    "                current = next_elem\n",
    "\n",
    "    # Clean up duplicate Volume II headers\n",
    "    volume_headers = soup.find_all('h3', string=lambda text: text and 'VOLUME II' in text.upper())\n",
    "    if len(volume_headers) > 1:\n",
    "        for header in volume_headers[1:]:\n",
    "            header.decompose()\n",
    "\n",
    "    return soup\n",
    "\n",
    "def create_chapter(title, content, idx, style_path=\"style/nav.css\"):\n",
    "    \"\"\"Create an EPUB chapter\"\"\"\n",
    "    chapter = epub.EpubHtml(\n",
    "        title=title,\n",
    "        file_name=f'chapter_{idx:03d}.xhtml',\n",
    "        lang='en'\n",
    "    )\n",
    "    \n",
    "    chapter.content = f'''\n",
    "    <html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
    "    <head>\n",
    "        <title>{escape(title)}</title>\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" href=\"{style_path}\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h2>{escape(title)}</h2>\n",
    "        {content}\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    \n",
    "    return chapter\n",
    "\n",
    "def remove_empty_pages(content):\n",
    "    # soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Iterate over all top-level elements (e.g., <body> children)\n",
    "    for element in soup.body.contents:\n",
    "        # Check if the element is empty or contains only whitespace\n",
    "        if not element.string.strip(): # and not element.find_all(recursive=False):\n",
    "            element.extract()\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Download the html file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/6941/6941-h/6941-h.htm\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Parse the html content and clean empty pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content,'html.parser')\n",
    "\n",
    "# clean_content = remove_empty_pages(soup)\n",
    "soup = clean_toc(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Extract Title from html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title.string if soup.title and soup.title.string else \"Libro de Ash\"\n",
    "title = clean_title(title)\n",
    "author = \"Sir Walter Scott\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Create the EPUB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = epub.EpubBook()\n",
    "book.set_identifier('id123456')   # this is a custom made identifier\n",
    "book.set_title(title)\n",
    "book.add_metadata('DC', 'language', 'en')\n",
    "# File Metadata\n",
    "book.add_metadata('DC', 'creator', author)\n",
    "book.add_metadata('DC', 'publisher', 'Project Gutenberg')\n",
    "book.add_metadata('DC', 'rights', 'Publi    c Domain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - We add some style to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ebooklib.epub.EpubItem at 0x1f60b43dc50>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style = '''\n",
    "@namespace epub \"http://www.idpf.org/2007/ops\";\n",
    "body {\n",
    "    font-family: \"Helvetica\", \"Arial\", sans-serif;\n",
    "    line-height: 1.5;\n",
    "    margin: 5%;\n",
    "}\n",
    "h1, h2, h3 { \n",
    "    text-align: center;\n",
    "    margin: 1em 0;\n",
    "}\n",
    "p { \n",
    "    text-indent: 1em;\n",
    "    margin: 0.5em 0;\n",
    "}\n",
    "'''\n",
    "nav_css = epub.EpubItem(\n",
    "    uid=\"style_nav\",\n",
    "    file_name=\"style/nav.css\",\n",
    "    media_type=\"text/css\",\n",
    "    content=style\n",
    ")\n",
    "book.add_item(nav_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Now we add the Cover Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"OM.jpg\", \"rb\") as file:\n",
    "        cover_content = file.read()\n",
    "        cover_image = epub.EpubItem(\n",
    "            uid=\"cover_image\",\n",
    "            file_name=\"images/cover.jpg\",\n",
    "            media_type=\"image/jpeg\",\n",
    "            content=cover_content\n",
    "        )\n",
    "        book.add_item(cover_image)\n",
    "        book.set_cover(\"images/cover.jpg\", cover_content)\n",
    "except FileNotFoundError:\n",
    "    print(\"Cover image not found, continuing without cover...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Add chapters to the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = []\n",
    "main_content = soup.find('body')\n",
    "if main_content:\n",
    "    chapter_markers = main_content.find_all(['h2', 'h3'])\n",
    "    \n",
    "    for idx, chapter_heading in enumerate(chapter_markers, 1):\n",
    "        chapter_title = chapter_heading.get_text().strip()\n",
    "        if not chapter_title:\n",
    "            continue\n",
    "            \n",
    "        # Collect each chapter content\n",
    "        chapter_content = []\n",
    "        current = chapter_heading.next_sibling\n",
    "        while current and current.name not in ['h2', 'h3']:\n",
    "            if hasattr(current, 'name'):\n",
    "                chapter_content.append(str(current))\n",
    "            current = current.next_sibling\n",
    "        \n",
    "        content_html = ''.join(chapter_content)\n",
    "        content_html = sanitize_html(content_html)\n",
    "        \n",
    "        # Create chapter\n",
    "        chapter = create_chapter(chapter_title, content_html, idx)\n",
    "        book.add_item(chapter)\n",
    "        chapters.append(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Generate Chapter List and Spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ebooklib.epub.EpubNav at 0x1f60d5a6990>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.toc = chapters\n",
    "book.spine = ['nav'] + chapters\n",
    "book.add_item(epub.EpubNav())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Write the Epub file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPUB file 'Old Mortality by Sir Walter Scott.epub' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "output_filename = f\"{clean_title(title)}.epub\"\n",
    "epub.write_epub(output_filename, book, {\n",
    "    'epub3_pages': False,\n",
    "    'spine_direction': 'ltr'\n",
    "})\n",
    "\n",
    "print(f\"EPUB file '{output_filename}' has been created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
